{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438f37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "ollama_url = 'http://localhost:11434/api/chat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f902a",
   "metadata": {},
   "source": [
    "# ZERO SHOT PROMPT ENGINEERING TECHNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68800cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Advancements in deep learning and neural networks continue to drive improvements in natural language processing, image recognition, and predictive analytics capabilities of AI systems.\n",
      "- The integration of edge computing with artificial intelligence is enabling faster decision making by reducing the need for data transmission between devices and central servers. This trend allows more real-time applications such as autonomous vehicles or smart cities to function efficiently. \n",
      "- Ethical considerations surrounding bias, privacy, transparency, and accountability in AI are becoming increasingly important topics of discussion among researchers, policymakers, and industry leaders alike.\n"
     ]
    }
   ],
   "source": [
    "def zero_shot_query(prompt:str, model:str='phi3:latest') -> str:\n",
    "    '''construct zero shot prompt and query model.'''\n",
    "    payload = {\n",
    "        'model':model,\n",
    "        'messages':[\n",
    "            {'role':'system', 'content':'You are an intelligent assistant.'},\n",
    "            {'role':'user', 'content':prompt}\n",
    "        ],\n",
    "        'options': {\n",
    "            'temperature': 0.0,\n",
    "            'num_predict': 300\n",
    "        },\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    response = requests.post(ollama_url, json=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = response.json()\n",
    "    return data['message']['content']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    prompt = 'Summarize AI trends in 3 bullet points.'\n",
    "    print(zero_shot_query(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e98a27",
   "metadata": {},
   "source": [
    "# FEW SHOT PROMPT ENGINEERING TECHNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b14fa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danke\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = [\n",
    "    {\"input\": \"Translate 'Hello' to Spanish\", \"output\": \"Hola\"},\n",
    "    {\"input\": \"Translate 'Goodbye' to French\", \"output\": \"Au revoir\"}\n",
    "]\n",
    "\n",
    "\n",
    "def few_shot_query(user_input: str, examples=EXAMPLES, model=\"phi3:latest\"):\n",
    "    \"\"\"Construct few-shot prompt and query model.\"\"\"\n",
    "    messages = [{'role':'system', 'content': 'you are an intelligent AI assistant.'}]\n",
    "\n",
    "    for ex in examples:\n",
    "        messages.append({'role':'user', 'content':ex['input']})\n",
    "        messages.append({'role':'assistant', 'content': ex['output']})\n",
    "\n",
    "    messages.append({'role':'user', 'content':user_input})\n",
    "    payload = {\n",
    "        'model':model,\n",
    "        'messages':messages,\n",
    "        'options':{'temperature': 0.0, 'num_predict': 300},\n",
    "        'stream': False\n",
    "    }\n",
    "\n",
    "    response = requests.post(ollama_url, json=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = response.json()\n",
    "    return data['message']['content']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = \"Translate 'Thank you' to German\"\n",
    "    print(few_shot_query(user_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RAG_projects)",
   "language": "python",
   "name": "rag_projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
